import express from 'express';
import OpenAI from 'openai';
import { v4 as uuidv4 } from 'uuid';
import dotenv from "dotenv";

dotenv.config();
const app = express();
const port = process.env.PORT || 3000;

app.use(express.json());

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

const sessions = new Map();

// --- System Prompt ---
const CARE_SYSTEM_PROMPT = `
You are "Care AI," an advanced, empathetic, and highly intelligent virtual health assistant for the "Care" mobile application.
Your primary role is to engage in supportive, multi-turn conversations with users about their health and well-being.
You are a crucial part of a larger ecosystem that includes a smartwatch for sensor data and a web application for doctors.

Your Core Directives:
8.  **Summarization (User-Facing & Doctor Prep):**
    *   Crucially, if you assess that the conversation contains significant information that a doctor should review (due to symptom severity, persistence, user concern, abnormal data, etc.), you should use the 'request_doctor_summary_generation' tool. You can also verbally inform the user that you think a summary for their doctor would be a good idea.
9.  **Escalation Awareness (Leading to Summary Request):** Based on the conversation and any data retrieved, if you determine the user's situation warrants review by their doctor, use the 'request_doctor_summary_generation' tool. Inform the user that you are flagging this for a more detailed summary which could be useful for their doctor.

Tool Usage Guidelines:
*   **request_doctor_summary_generation**:
    *   **Purpose**: To flag that the current conversation has reached a point where a detailed summary and an AI assessment for a doctor should be generated by the system. This is a backend process you are initiating.
    *   **Arguments**:
        *   \`userId\` (string, mandatory): The ID of the user.
        *   \`reason\` (string, mandatory): A brief reason why you believe a summary for the doctor is now warranted.
    *   **When to Use**: When you, Care AI, assess that the conversation contains significant information that a doctor should review.
`; // (Rest of your detailed prompt)


// Corrected traceStep function
const traceStep = (passedTraceId, stepName, metadata = {}) => {
    const currentTraceId = passedTraceId || 'TRACE_ID_MISSING_' + uuidv4();
    console.log(`[Trace ID: ${currentTraceId}] [Step: ${stepName}]`, JSON.stringify(metadata));
};

const mockLangSmithMiddleware = (req, res, next) => {
    req.traceId = uuidv4();
    // Use the corrected traceStep here, passing req.traceId
    traceStep(req.traceId, `Starting new request: ${req.method} ${req.originalUrl}`, {});
    next();
};
app.use(mockLangSmithMiddleware);


// --- Tool Definitions ---
const tools = [
    { type: "function", function: { name: "get_telemetry_data", /* ... */ parameters: { type: "object", properties: { userId: { type: "string"}}, required: ["userId"]}}},
    { type: "function", function: { name: "get_user_health_data", /* ... */ parameters: { type: "object", properties: { userId: { type: "string"}}, required: ["userId"]}}},
    { type: "function", function: { name: "get_current_location", /* ... */ parameters: { type: "object", properties: { userId: { type: "string"}}, required: ["userId"]}}},
    { type: "function", function: { name: "request_doctor_summary_generation", description: "Flags that a detailed summary and AI assessment for a doctor should be generated.", parameters: { type: "object", properties: { userId: { type: "string" }, reason: { type: "string" }}, required: ["userId", "reason"]}}},
];

// --- Mock Tool Implementations ---
async function get_telemetry_data(userId, traceId) {
    traceStep(traceId, "get_telemetry_data_called", { userId });
    return JSON.stringify({ avgHR: 70, maxHR: 100, minHR: 60, avgSpo2: 98, timestamp: new Date().toISOString() });
}

async function get_user_health_data(userId, traceId) {
    traceStep(traceId, "get_user_health_data_called", { userId });
    const mockUserData = { user123: { diagnosis: ["Test"], allergies: [], medications: [], age: 30, weightKg: 70, heightCm: 170 }};
    return JSON.stringify(mockUserData[userId] || mockUserData.default);
}

async function get_current_location(userId, traceId) {
    traceStep(traceId, "get_current_location_called", { userId });
    return JSON.stringify({ latitude: 34.0522, longitude: -118.2437, timestamp: new Date().toISOString() });
}

async function request_doctor_summary_generation(userId, reason, conversationHistory, traceId) {
    traceStep(traceId, "request_doctor_summary_generation_tool_called", { userId, reason });
    generateAndLogDoctorSummary(userId, conversationHistory, reason, traceId)
        .catch(error => {
            console.error(`[Trace ID: ${traceId}] Error in background summary generation:`, error.message);
            traceStep(traceId, "background_summary_generation_error", { error: error.message });
        });
    return JSON.stringify({ status: "Doctor summary generation initiated.", reason_received: reason });
}

const availableTools = { get_telemetry_data, get_user_health_data, get_current_location, request_doctor_summary_generation };

// --- Doctor Summary Generation ---
async function generateAndLogDoctorSummary(userId, conversationHistory, reasonFromAI, traceId) {
    traceStep(traceId, "generate_doctor_summary_started", { userId, reasonFromAI });
    const summarizationPrompt = `
Conversation History (last 10 relevant messages):
${JSON.stringify(conversationHistory.filter(m => m.role === 'user' || m.role === 'assistant').slice(-10), null, 2)}

Task: Based ONLY on the provided conversation history:
1. summaryForDoctor: (string) Concise, structured summary (complaints, symptoms, data, concerns).
2. aiPotentialAssessment: (string) "AI Potential Assessment (not a diagnosis): Possible [general issue category]. Medical evaluation needed."
3. recommendEscalation: (boolean) True/false for doctor review.
4. escalationReason: (string) Brief reason for escalation recommendation.
Return as a single, minified JSON object with these keys.
Original AI reason for this request: ${reasonFromAI}
    `;
    try {
        const summaryCompletion = await openai.chat.completions.create({
            model: "gpt-4o", messages: [{ role: "system", content: "You are a medical summarization assistant outputting JSON." },{ role: "user", content: summarizationPrompt }],
            temperature: 0.2, max_tokens: 700, response_format: { type: "json_object" },
        });
        const summaryResultString = summaryCompletion.choices[0].message.content;
        traceStep(traceId, "doctor_summary_generated_raw_content", { length: summaryResultString?.length });

        let parsedSummary;
        try {
            parsedSummary = JSON.parse(summaryResultString);
            parsedSummary.originalAiReasonForSummary = reasonFromAI;
            parsedSummary.summaryGeneratedAt = new Date().toISOString();

            if (sessions.has(userId)) {
                const sessionData = sessions.get(userId);
                sessionData.latestDoctorSummary = parsedSummary; // sessions.set(userId, sessionData) not strictly needed if sessionData is a reference
                traceStep(traceId, "doctor_summary_stored_in_session", { userId });
            } else {
                traceStep(traceId, "doctor_summary_not_stored_session_missing", { userId });
            }
        } catch (e) {
            console.error(`[Trace ID: ${traceId}] Could not parse summary JSON from model:`, e.message, "Raw:", summaryResultString);
            traceStep(traceId, "doctor_summary_parsing_failed", { error: e.message, rawSubstr: summaryResultString?.substring(0,100) });
            parsedSummary = { error: "Failed to parse summary from AI.", raw: summaryResultString, originalAiReasonForSummary: reasonFromAI, summaryGeneratedAt: new Date().toISOString() };
            if (sessions.has(userId)) sessions.get(userId).latestDoctorSummary = parsedSummary;
        }

        console.log(`\n--- [Trace ID: ${traceId}] DOCTOR SUMMARY FOR USER: ${userId} ---`);
        console.log(JSON.stringify(parsedSummary, null, 2));
        console.log("--- END OF DOCTOR SUMMARY ---\n");

    } catch (error) {
        console.error(`[Trace ID: ${traceId}] Error generating doctor summary:`, error.message, error.stack);
        traceStep(traceId, "doctor_summary_generation_failed", { error: error.message });
        if (sessions.has(userId)) sessions.get(userId).latestDoctorSummary = { error: `Summary generation failed: ${error.message}`, originalAiReasonForSummary: reasonFromAI, summaryGeneratedAt: new Date().toISOString() };
    }
}

// --- Chat POST Route ---
app.post('/chat', async (req, res) => {
    const { userId, message } = req.body;
    const traceId = req.traceId; // Established by middleware

    traceStep(traceId, 'request_received', { userId, messageContent: message?.substring(0, 50) + "..." });

    if (!userId || !message) {
        traceStep(traceId, 'input_validation_failed', { reason: 'Missing userId or message' });
        return res.status(400).json({ text: "Missing userId or message.", trace: [], usage: {} });
    }

    if (!sessions.has(userId)) {
        traceStep(traceId, 'new_session_created', { userId });
        sessions.set(userId, { history: [{ role: 'system', content: CARE_SYSTEM_PROMPT }], latestDoctorSummary: null });
    }

    const session = sessions.get(userId);
    session.history.push({ role: 'user', content: message });
    traceStep(traceId, 'user_message_added_to_history', { count: session.history.length });

    let assistantResponsePayload = { text: "Error processing request.", trace: [], usage: {} };

    try {
        // ... (simulated error logic if any) ...

        traceStep(traceId, 'calling_openai_model_initial', { historyLength: session.history.length });
        let completion = await openai.chat.completions.create({
            model: "gpt-4o", messages: session.history, temperature: 0.7, max_tokens: 300, tools: tools, tool_choice: "auto",
        });
        traceStep(traceId, 'openai_model_responded_initial', { choice: completion.choices[0].message });

        let assistantMessage = completion.choices[0].message;
        assistantResponsePayload.usage = completion.usage || { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 };

        if (assistantMessage.tool_calls?.length > 0) {
            traceStep(traceId, 'tool_calls_requested', { calls: assistantMessage.tool_calls.map(tc => tc.function.name) });
            session.history.push(assistantMessage);

            for (const toolCall of assistantMessage.tool_calls) {
                const functionName = toolCall.function.name;
                const functionToCall = availableTools[functionName];
                const functionArgs = JSON.parse(toolCall.function.arguments);
                let functionResponse = JSON.stringify({error: "Tool not found or failed before execution"});

                traceStep(traceId, `executing_tool_${functionName}`, { args: functionArgs });
                if (functionToCall) {
                    try {
                        if (functionName === "request_doctor_summary_generation") {
                            functionResponse = await functionToCall(functionArgs.userId, functionArgs.reason, session.history, traceId);
                        } else {
                            functionResponse = await functionToCall(functionArgs.userId, traceId);
                        }
                        traceStep(traceId, `tool_${functionName}_executed_successfully`, { responseSubstr: String(functionResponse).substring(0,70) });
                    } catch (toolError) {
                        console.error(`[Trace ID: ${traceId}] Tool ${functionName} error:`, toolError.message);
                        traceStep(traceId, `tool_${functionName}_execution_failed`, { error: toolError.message });
                        functionResponse = JSON.stringify({ error: "Tool execution failed", details: toolError.message });
                    }
                }
                session.history.push({ tool_call_id: toolCall.id, role: "tool", name: functionName, content: functionResponse });
            }

            traceStep(traceId, 'calling_openai_model_after_tools', { historyLength: session.history.length });
            const secondCompletion = await openai.chat.completions.create({
                model: "gpt-4o", messages: session.history, temperature: 0.7, max_tokens: 250,
            });
            traceStep(traceId, 'openai_model_responded_after_tools', { choice: secondCompletion.choices[0].message });
            assistantMessage = secondCompletion.choices[0].message;
            if (secondCompletion.usage) {
                 assistantResponsePayload.usage.prompt_tokens += secondCompletion.usage.prompt_tokens;
                 assistantResponsePayload.usage.completion_tokens += secondCompletion.usage.completion_tokens;
                 assistantResponsePayload.usage.total_tokens += secondCompletion.usage.total_tokens;
            }
        }

        assistantResponsePayload.text = assistantMessage.content || "No textual content from assistant.";
        session.history.push({ role: 'assistant', content: assistantResponsePayload.text });
        traceStep(traceId, 'assistant_message_added_to_history', { count: session.history.length });
        assistantResponsePayload.trace.push({ step: 'assistant_response_generated' });

    } catch (error) {
        console.error(`[Trace ID: ${traceId}] Error in /chat:`, error.message, error.stack);
        traceStep(traceId, 'chat_route_processing_error', { error: error.message });
        assistantResponsePayload.text = `Error: ${error.message}`;
    }
    res.json(assistantResponsePayload);
});

// --- GET Doctor Summary Endpoint ---
app.get('/chat/:userId/doctorsummary', (req, res) => {
    const { userId } = req.params;
    const traceId = req.traceId; // From middleware

    traceStep(traceId, 'doctorsummary_request_received', { userId });

    if (sessions.has(userId)) {
        const sessionData = sessions.get(userId);
        if (sessionData.latestDoctorSummary) {
            traceStep(traceId, 'doctorsummary_found_and_returned', { userId });
            res.json(sessionData.latestDoctorSummary);
        } else {
            traceStep(traceId, 'doctorsummary_not_yet_available', { userId });
            res.status(404).json({ message: "Doctor summary not yet available." });
        }
    } else {
        traceStep(traceId, 'doctorsummary_user_session_not_found', { userId });
        res.status(404).json({ message: "User session not found." });
    }
});

app.listen(port, () => {
    console.log(`Care AI Chatbot server listening at http://localhost:${port}`);
    console.log("OpenAI API Key Loaded:", !!process.env.OPENAI_API_KEY);
});